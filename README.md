# ml-refs

Useful open source references for studying ML. Quality over quantity.

## Backprop Libraries

Ordered by ascending complexity.

- [Andrej Karpathy: micrograd](https://github.com/karpathy/micrograd)
- [George Hotz: teenygrad](https://github.com/tinygrad/teenygrad)
- [George Hotz tinygrad](https://github.com/tinygrad)

## Deep Learning

 - Complete course including The Little Book of Deep Learning by Fran√ßois Fleuret from University of Geneva: [Deep Learning Course](https://fleuret.org/dlc/)
 - The complete [CS231n: Deep Learning for Computer Vision](http://cs231n.stanford.edu/schedule.html) lecture has a great introduction to Deep Learning basics, especially backpropagation. It is run by Fei-Fei Li but Andrej Karpathy worked a lot on the material, too. 

## Generative Models

 - Complete lecture with videos by Volodymyr Kuleshov from Cornell University: [CS 6785 Deep Probabilistic and Generative Models 2023](https://canvas.cornell.edu/courses/50665)

## Hyperparameter Optimization

 - Google's [Deep Learning Tuning Playbook](https://github.com/google-research/tuning_playbook)

## Reinforcement Learning

 Complete course with videos by Paderborn University: [Reinforcement Learning](https://github.com/upb-lea/reinforcement_learning_course_materials)

## Transformers

 -  Lecture slides by John Hewitt from CS 234N (NLP with DL) at Stanford University in 2023: [Lecture 8: Self-Attention and Transformers](https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture08-transformers.pdf)
 - Video by Niels Rogge about [how a Transformer works at inference vs. training time
](https://www.youtube.com/watch?v=IGu7ivuy1Ag)
